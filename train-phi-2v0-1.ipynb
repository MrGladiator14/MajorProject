{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U \"huggingface_hub[cli]\"\n!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"\n!pip install transformers --upgrade\n!git config --global credential.helper cache\n!git config --global credential.helper manager","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T08:17:53.780697Z","iopub.execute_input":"2024-04-24T08:17:53.780969Z","iopub.status.idle":"2024-04-24T08:18:34.421169Z","shell.execute_reply.started":"2024-04-24T08:17:53.780944Z","shell.execute_reply":"2024-04-24T08:18:34.419963Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub[cli] in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.9.0)\nCollecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\nCollecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.42)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub[cli]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2024.2.2)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\nDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\nInstalling collected packages: pfzy, InquirerPy\nSuccessfully installed InquirerPy-0.3.4 pfzy-0.3.4\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nCollecting transformers\n  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nCollecting tokenizers<0.20,>=0.19 (from transformers)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nDownloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\nSuccessfully installed tokenizers-0.19.1 transformers-4.40.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install cubinlinker cupy-cuda11x ptxcompiler dill==0.3.1.1 protobuf==3.12.2 pyarrow==11.0.0 pandas==1.5.0 dask==2023.7.1","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:18:34.423463Z","iopub.execute_input":"2024-04-24T08:18:34.424157Z","iopub.status.idle":"2024-04-24T08:18:36.382438Z","shell.execute_reply.started":"2024-04-24T08:18:34.424114Z","shell.execute_reply":"2024-04-24T08:18:36.381467Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement cubinlinker (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for cubinlinker\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade protobuf","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:18:36.383713Z","iopub.execute_input":"2024-04-24T08:18:36.383984Z","iopub.status.idle":"2024-04-24T08:18:49.409995Z","shell.execute_reply.started":"2024-04-24T08:18:36.383955Z","shell.execute_reply":"2024-04-24T08:18:49.409062Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (3.20.3)\nCollecting protobuf\n  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nDownloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 5.26.1 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 5.26.1 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngoogle-ai-generativelanguage 0.6.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-artifact-registry 1.10.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-dlp 3.14.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-monitoring 2.18.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-recommendations-ai 0.7.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-resource-manager 1.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-spanner 3.40.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-videointelligence 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\ngoogleapis-common-protos 1.62.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\ngrpc-google-iam-v1 0.12.7 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 5.26.1 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 5.26.1 which is incompatible.\nopentelemetry-proto 1.22.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.26.1 which is incompatible.\nproto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\ntensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 5.26.1 which is incompatible.\ntensorboard-plugin-profile 2.15.0 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.26.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\ntensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.26.1 which is incompatible.\ntensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.26.1 which is incompatible.\nwandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 5.26.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-4.21.12\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos._exit(00)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:22:01.703572Z","iopub.execute_input":"2024-04-24T08:22:01.703938Z","iopub.status.idle":"2024-04-24T08:22:15.119711Z","shell.execute_reply.started":"2024-04-24T08:22:01.703907Z","shell.execute_reply":"2024-04-24T08:22:15.118656Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:22:15.121722Z","iopub.execute_input":"2024-04-24T08:22:15.122037Z","iopub.status.idle":"2024-04-24T08:22:32.259374Z","shell.execute_reply.started":"2024-04-24T08:22:15.122010Z","shell.execute_reply":"2024-04-24T08:22:32.258607Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-24 08:22:24.135129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-24 08:22:24.135234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-24 08:22:24.262268: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED']=\"true\"","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:22:32.260522Z","iopub.execute_input":"2024-04-24T08:22:32.261081Z","iopub.status.idle":"2024-04-24T08:22:32.265628Z","shell.execute_reply.started":"2024-04-24T08:22:32.261054Z","shell.execute_reply":"2024-04-24T08:22:32.264489Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"huggingface_dataset_name = \"Bry14/PHagenlocher-HaskellYTv0.1\"\ndataset = load_dataset(huggingface_dataset_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:22:32.267430Z","iopub.execute_input":"2024-04-24T08:22:32.267692Z","iopub.status.idle":"2024-04-24T08:22:36.954513Z","shell.execute_reply.started":"2024-04-24T08:22:32.267669Z","shell.execute_reply":"2024-04-24T08:22:36.953751Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d5ea2fb9864442d98c25620f8b3beaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/134k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2feb9b4dd4a42048df794d190757f11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/712 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93ea967d938c4714b8f180bd692ec5e1"}},"metadata":{}}]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float32\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:22:36.955485Z","iopub.execute_input":"2024-04-24T08:22:36.955737Z","iopub.status.idle":"2024-04-24T08:22:36.961972Z","shell.execute_reply.started":"2024-04-24T08:22:36.955715Z","shell.execute_reply":"2024-04-24T08:22:36.961095Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name='microsoft/phi-2'\ndevice_map = {\"\": 0}\noriginal_model = AutoModelForCausalLM.from_pretrained(model_name, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:22:36.963371Z","iopub.execute_input":"2024-04-24T08:22:36.963647Z","iopub.status.idle":"2024-04-24T08:23:03.348860Z","shell.execute_reply.started":"2024-04-24T08:22:36.963625Z","shell.execute_reply":"2024-04-24T08:23:03.347866Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08b200aac8a24ea780d92afc2325ff02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi.py:   0%|          | 0.00/9.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"578b2c1c068c42a185b0845bae607efc"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- configuration_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi.py:   0%|          | 0.00/62.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72cc60e2f214f52b97d8e3c8293a63a"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- modeling_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f291ecbf5b6437d81457c5385803f56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99785cc8bc3c4a34afaa941cac5545fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"874fbd0b43cc4d078a400bac9f124cf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2677cfd63d774dd1bf7ae86605c49242"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc73b724a2d4dbab9031ccd5374dcd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1300f5bee72b47bcb94b29b2425d9add"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:03.350614Z","iopub.execute_input":"2024-04-24T08:23:03.351092Z","iopub.status.idle":"2024-04-24T08:23:06.027702Z","shell.execute_reply.started":"2024-04-24T08:23:03.351057Z","shell.execute_reply":"2024-04-24T08:23:06.026851Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7daf3847cbe54c76982334d672b8512b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdad3327f9ff4d21a6172c2ef666fb10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01be90f9def546fcbd7361f4322095eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbbc1b3aebb24df486b09d0869a058d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7618f4b6bbe4360916e683328a96025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"994a24b6e28e4bb2a71ab3db8e5e7cc9"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers.trainer_utils import set_seed\n!pip install tensorflow\nimport tensorflow as tf\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:06.029167Z","iopub.execute_input":"2024-04-24T08:23:06.029545Z","iopub.status.idle":"2024-04-24T08:23:22.617496Z","shell.execute_reply.started":"2024-04-24T08:23:06.029511Z","shell.execute_reply":"2024-04-24T08:23:22.616352Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.12)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"def gen(model, prompt, max_length):\n    inputs = tokenizer(prompt, return_tensors='pt')\n    outputs = model.generate(inputs['input_ids'], max_length=max_length)\n    return tokenizer.decode(outputs[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:22.619336Z","iopub.execute_input":"2024-04-24T08:23:22.620070Z","iopub.status.idle":"2024-04-24T08:23:22.626567Z","shell.execute_reply.started":"2024-04-24T08:23:22.620030Z","shell.execute_reply":"2024-04-24T08:23:22.624846Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"%%time\nseed = 42\nset_seed(seed)\n\nindex = 9\n\nprompt = dataset['train'][index]['Description']\nresp = dataset['train'][index]['Statement']\n\nformatted_prompt = f\"Instruct: You are a helpful assistant who is proficient in haskell programming language, return only code in only haskell programming language.\\n{prompt}\\nOutput:\\n\"\nres = gen(original_model,formatted_prompt,512,)\nprint(res)\noutput = res.split('Output:\\n')[1]\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{formatted_prompt}')\nprint(dash_line)\nprint(f'RESPONSE:\\n{resp}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:22.630061Z","iopub.execute_input":"2024-04-24T08:23:22.630427Z","iopub.status.idle":"2024-04-24T08:23:24.345302Z","shell.execute_reply.started":"2024-04-24T08:23:22.630402Z","shell.execute_reply":"2024-04-24T08:23:24.344365Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"<|endoftext|>Instruct: You are a helpful assistant who is proficient in haskell programming language, return only code in only haskell programming language.\nConditional Statement that evaluates 'z'. If 'z' is true, evaluates 'x'; otherwise, evaluates 'y'.\nOutput:\n\nif z == true then x else y\n<|endoftext|>\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\nInstruct: You are a helpful assistant who is proficient in haskell programming language, return only code in only haskell programming language.\nConditional Statement that evaluates 'z'. If 'z' is true, evaluates 'x'; otherwise, evaluates 'y'.\nOutput:\n\n---------------------------------------------------------------------------------------------------\nRESPONSE:\nif z then x else y\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n\nif z == true then x else y\n<|endoftext|>\nCPU times: user 1.29 s, sys: 125 ms, total: 1.41 s\nWall time: 1.7 s\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_prompt_formats(sample):\n    \"\"\"\n    Format various fields of the sample ('instruction','output')\n    Then concatenate them using two newline characters \n    :param sample: Sample dictionnary\n    \"\"\"\n    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n    INSTRUCTION_KEY = \"### Instruct: You are a helpful assistant who is proficient in haskell programming language, return code in only haskell programming language.\"\n    RESPONSE_KEY = \"### Output:\"\n    END_KEY = \"### End\"\n    \n    blurb = f\"\\n{INTRO_BLURB}\"\n    instruction = f\"{INSTRUCTION_KEY}\"\n    input_context = f\"{sample['Description']}\" if sample[\"Description\"] else None\n    response = f\"{RESPONSE_KEY}\\n{sample['Statement']}\"\n    end = f\"{END_KEY}\"\n    \n    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n\n    formatted_prompt = \"\\n\\n\".join(parts)\n    sample[\"text\"] = formatted_prompt\n\n    return sample","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:24.346627Z","iopub.execute_input":"2024-04-24T08:23:24.346975Z","iopub.status.idle":"2024-04-24T08:23:24.354053Z","shell.execute_reply.started":"2024-04-24T08:23:24.346950Z","shell.execute_reply":"2024-04-24T08:23:24.353158Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\n# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\ndef get_max_length(model):\n    conf = model.config\n    max_length = None\n    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n        max_length = getattr(model.config, length_setting, None)\n        if max_length:\n            print(f\"Found max lenth: {max_length}\")\n            break\n    if not max_length:\n        max_length = 1024\n        print(f\"Using default max length: {max_length}\")\n    return max_length\n\n\ndef preprocess_batch(batch, tokenizer, max_length):\n    \"\"\"\n    Tokenizing a batch\n    \"\"\"\n    return tokenizer(\n        batch[\"text\"],\n        max_length=max_length,\n        truncation=True,\n    )\n\n# SOURCE https://github.com/databrickslabs/dolly/blob/master/training/trainer.py\ndef preprocess_dataset(tokenizer: AutoTokenizer, max_length: int,seed, dataset):\n    \"\"\"Format & tokenize it so it is ready for training\n    :param tokenizer (AutoTokenizer): Model Tokenizer\n    :param max_length (int): Maximum number of tokens to emit from tokenizer\n    \"\"\"\n    \n    # Add prompt to each sample\n    print(\"Preprocessing dataset...\")\n    dataset = dataset.map(create_prompt_formats)#, batched=True)\n    \n    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n    dataset = dataset.map(\n        _preprocessing_function,\n        batched=True,\n        remove_columns=['Statement', 'Description'],\n    )\n\n    # Filter out samples that have input_ids exceeding max_length\n    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n    \n    # Shuffle dataset\n    dataset = dataset.shuffle(seed=seed)\n\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:24.355323Z","iopub.execute_input":"2024-04-24T08:23:24.355602Z","iopub.status.idle":"2024-04-24T08:23:24.370858Z","shell.execute_reply.started":"2024-04-24T08:23:24.355572Z","shell.execute_reply":"2024-04-24T08:23:24.370083Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"## Pre-process dataset\nmax_length = get_max_length(original_model)\nprint(max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:24.371870Z","iopub.execute_input":"2024-04-24T08:23:24.372167Z","iopub.status.idle":"2024-04-24T08:23:24.386606Z","shell.execute_reply.started":"2024-04-24T08:23:24.372144Z","shell.execute_reply":"2024-04-24T08:23:24.385648Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Found max lenth: 2048\n2048\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['train'])\n# eval_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['validation'])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:24.387522Z","iopub.execute_input":"2024-04-24T08:23:24.387769Z","iopub.status.idle":"2024-04-24T08:23:27.552268Z","shell.execute_reply.started":"2024-04-24T08:23:24.387747Z","shell.execute_reply":"2024-04-24T08:23:27.551485Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Preprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/712 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f98d417326e45209e84ac33766270dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/712 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96524239ac5e40c8888ec402f9e213a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/712 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"336637758f3c4ebba28fc92ba1e1abda"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n# 2 - Using the prepare_model_for_kbit_training method from PEFT\n# Preparing the Model for QLoRA\noriginal_model = prepare_model_for_kbit_training(original_model)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:27.553405Z","iopub.execute_input":"2024-04-24T08:23:27.553689Z","iopub.status.idle":"2024-04-24T08:23:27.572061Z","shell.execute_reply.started":"2024-04-24T08:23:27.553664Z","shell.execute_reply":"2024-04-24T08:23:27.571236Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"config = LoraConfig(\n    r=32, #Rank\n    lora_alpha=32,\n    target_modules=[\n        'q_proj',\n        'k_proj',\n        'v_proj',\n        'dense'\n    ],\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    task_type=\"CAUSAL_LM\",\n)\n\n# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\noriginal_model.gradient_checkpointing_enable()\n\npeft_model = get_peft_model(original_model, config)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:27.573135Z","iopub.execute_input":"2024-04-24T08:23:27.573415Z","iopub.status.idle":"2024-04-24T08:23:28.013132Z","shell.execute_reply.started":"2024-04-24T08:23:27.573393Z","shell.execute_reply":"2024-04-24T08:23:28.012166Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# for name, param in peft_model.named_parameters():\n#     if param.requires_grad:\n#         print(name)\n# # Assuming 'model' is your model\n# for name, param in peft_model.named_parameters():\n#     print(name, param)\n# num_trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n# print(f'The model has {num_trainable_params} trainable parameters.')\n# total_params = sum(p.numel() for p in peft_model.parameters())\n# print(f'The model has {total_params} total parameters.')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-04-24T08:23:28.014361Z","iopub.execute_input":"2024-04-24T08:23:28.014650Z","iopub.status.idle":"2024-04-24T08:23:28.018907Z","shell.execute_reply.started":"2024-04-24T08:23:28.014625Z","shell.execute_reply":"2024-04-24T08:23:28.017958Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"output_dir = f'./peft-Haskell-training-{str(int(time.time()))}'\nimport transformers\n\npeft_training_args = TrainingArguments(\n    output_dir = output_dir,\n    warmup_steps=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    num_train_epochs=10,\n    learning_rate=2e-4,\n    optim=\"paged_adamw_8bit\",\n    logging_steps=25,\n    logging_dir=\"./logs\",\n    save_strategy=\"steps\",\n    save_steps=25,\n    evaluation_strategy=\"no\",  # Set evaluation_strategy to \"no\" to disable evaluation\n    eval_steps=25,\n    do_eval=False,  # Set do_eval to False to disable evaluation\n    gradient_checkpointing=True,\n    report_to=\"none\",\n    overwrite_output_dir = 'True',\n    group_by_length=True,\n)\n\npeft_model.config.use_cache = False\n\npeft_trainer = transformers.Trainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    # eval_dataset=eval_dataset,  # Comment out or remove this line\n    args=peft_training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:28.020245Z","iopub.execute_input":"2024-04-24T08:23:28.020548Z","iopub.status.idle":"2024-04-24T08:23:28.076063Z","shell.execute_reply.started":"2024-04-24T08:23:28.020526Z","shell.execute_reply":"2024-04-24T08:23:28.075344Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# # Calculate the number of training steps per epoch\n# steps_per_epoch = len(train_dataset) // peft_training_args.per_device_train_batch_size\n\n# # Set the number of epochs\n# num_epochs = 10  # Increase this to increase the number of epochs\n\n# # Set max_steps to steps_per_epoch times num_epochs\n# peft_training_args.max_steps = steps_per_epoch * num_epochs","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:28.077167Z","iopub.execute_input":"2024-04-24T08:23:28.077459Z","iopub.status.idle":"2024-04-24T08:23:28.081533Z","shell.execute_reply.started":"2024-04-24T08:23:28.077435Z","shell.execute_reply":"2024-04-24T08:23:28.080664Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"%%time\npeft_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-24T08:23:28.082801Z","iopub.execute_input":"2024-04-24T08:23:28.083137Z","iopub.status.idle":"2024-04-24T09:51:56.145748Z","shell.execute_reply.started":"2024-04-24T08:23:28.083106Z","shell.execute_reply":"2024-04-24T09:51:56.144731Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1780' max='1780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1780/1780 1:28:22, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.618600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.755100</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.760100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.690500</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.690300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.762500</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.568600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.747500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.556600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.698400</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.610200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.546500</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.616800</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.491500</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.580300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.430100</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.576900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.480900</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.494000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.506100</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.468300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.476900</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.361900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.496300</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.373000</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.445800</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.412800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.381400</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>0.407200</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.316100</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>0.375600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.280900</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>0.405300</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.307500</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>0.374900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.317900</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.249000</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.328200</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>0.261600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.318600</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>0.267500</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.328200</td>\n    </tr>\n    <tr>\n      <td>1075</td>\n      <td>0.276300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.255800</td>\n    </tr>\n    <tr>\n      <td>1125</td>\n      <td>0.225400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.213400</td>\n    </tr>\n    <tr>\n      <td>1175</td>\n      <td>0.294500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.224400</td>\n    </tr>\n    <tr>\n      <td>1225</td>\n      <td>0.296300</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.237300</td>\n    </tr>\n    <tr>\n      <td>1275</td>\n      <td>0.214100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.227500</td>\n    </tr>\n    <tr>\n      <td>1325</td>\n      <td>0.217800</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.241700</td>\n    </tr>\n    <tr>\n      <td>1375</td>\n      <td>0.195500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.234700</td>\n    </tr>\n    <tr>\n      <td>1425</td>\n      <td>0.191800</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.215700</td>\n    </tr>\n    <tr>\n      <td>1475</td>\n      <td>0.203500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.185100</td>\n    </tr>\n    <tr>\n      <td>1525</td>\n      <td>0.201400</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.173900</td>\n    </tr>\n    <tr>\n      <td>1575</td>\n      <td>0.214300</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.174500</td>\n    </tr>\n    <tr>\n      <td>1625</td>\n      <td>0.214300</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.175400</td>\n    </tr>\n    <tr>\n      <td>1675</td>\n      <td>0.178600</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.189600</td>\n    </tr>\n    <tr>\n      <td>1725</td>\n      <td>0.174000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.189500</td>\n    </tr>\n    <tr>\n      <td>1775</td>\n      <td>0.159200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 1h 12min 48s, sys: 15min 26s, total: 1h 28min 14s\nWall time: 1h 28min 28s\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1780, training_loss=0.3842785360103243, metrics={'train_runtime': 5307.4719, 'train_samples_per_second': 1.342, 'train_steps_per_second': 0.335, 'total_flos': 1.11167858110464e+16, 'train_loss': 0.3842785360103243, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"# %%time\n# trainer.train(resume_from_checkpoint='path_to_your_checkpoint')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/working/phi-1_5-SFT-haskell-v0.1\"\n\nif os.path.exists(model_path):\n    print(\"Path exists.\")\nelse:\n    print(\"Path does not exist.\")\npeft_trainer.save_model(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n!sudo apt-get install git-lfs\n!git lfs install\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface-cli","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"HUGGINGFACE_TOKEN\"] = \"your_token\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://huggingface.co/Bry14/phi-1_5-SFT-haskell-v0.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git config --global user.email \"brysongracias@gmail.com\"\n!git config --global user.name \"Byson Gracias\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd phi-1_5-SFT-haskell-v0.1 && git add . && git commit -m \"Add fine-tuned model\" && git push\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv ./* ./Bry14/phi-1_5-SFT-haskell-v0.1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}